{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad80858d",
   "metadata": {},
   "source": [
    "### 단일모델링 (Segment_A~E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# local\n",
    "root_path = '../data/open'\n",
    "\n",
    "# colab\n",
    "# root_path = '/content/drive/MyDrive/12조 파이널프로젝트/data'\n",
    "\n",
    "# 데이터 불러오기\n",
    "\n",
    "#train_file = '201812_processed_All'\n",
    "#train_file = '201812_corr_drop_All'\n",
    "#file_name = 'corr_drop_All'\n",
    "#file_name = '201812_vif_drop_All'\n",
    "file_name = '201812_vif_drop_threshold20'\n",
    "train_df = pd.read_parquet(f'{root_path}/train/{file_name}.parquet')\n",
    "\n",
    "test_file = f'{root_path}/test/201812_processed_All.parquet'\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "# 타겟 레이블 재구성\n",
    "def get_target_label(df):\n",
    "    segment_columns = ['Segment_A', 'Segment_B', 'Segment_C', 'Segment_D', 'Segment_E']\n",
    "    return df[segment_columns].idxmax(axis=1).str[-1]\n",
    "\n",
    "# 타겟 생성\n",
    "train_df['Segment'] = get_target_label(train_df)\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X = train_df.drop(columns=['Segment_A', 'Segment_B', 'Segment_C', 'Segment_D', 'Segment_E', 'Segment', 'ID', '기준년월'])\n",
    "y = train_df['Segment']\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X.columns if col in test_df.columns]\n",
    "X = X[common_cols]\n",
    "X_test = test_df[common_cols]\n",
    "\n",
    "# 학습/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# CatBoost 모델 정의 및 학습\n",
    "'''\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='TotalF1:average=Micro',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "'''\n",
    "model = CatBoostClassifier(verbose=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 성능 평가\n",
    "y_pred_val = model.predict(X_val)\n",
    "f1 = f1_score(y_val, y_pred_val, average='micro')\n",
    "print(f\"Validation F1 score (micro): {f1:.4f}\")\n",
    "\n",
    "# 최종 예측\n",
    "y_pred_test = model.predict(X_test).flatten()\n",
    "\n",
    "# 제출파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'Segment': y_pred_test\n",
    "})\n",
    "\n",
    "submission.to_csv(f'../results/{file_name}_catboost_submission.csv', index=False)\n",
    "print(f\"{file_name}_submission 저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64129f",
   "metadata": {},
   "source": [
    "### 단일 모델링 (Segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cefcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# local\n",
    "root_path = '../data/open'\n",
    "\n",
    "# colab\n",
    "# root_path = '/content/drive/MyDrive/12조 파이널프로젝트/data'\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_name = 'vif_one_segment' # 이 부분만 수정하여 모델1,2,3 똑같이 검정\n",
    "train_df = pd.read_parquet(f'{root_path}/train/{file_name}.parquet')\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X = train_df.drop(columns=['ID', '기준년월', 'Segment'])\n",
    "y = train_df['Segment']\n",
    "\n",
    "test_file = f'{root_path}/test/201812_processed_All.parquet'\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X.columns if col in test_df.columns]\n",
    "X = X[common_cols]\n",
    "X_test = test_df[common_cols]\n",
    "\n",
    "# 학습/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# CatBoost 모델 정의 및 학습\n",
    "'''\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='TotalF1:average=Micro',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "'''\n",
    "model = CatBoostClassifier(verbose=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 성능 평가\n",
    "y_pred_val = model.predict(X_val)\n",
    "f1 = f1_score(y_val, y_pred_val, average='micro')\n",
    "print(f\"Validation F1 score (micro): {f1:.4f}\")\n",
    "\n",
    "# 혼동행렬\n",
    "# 혼동행렬을 DataFrame으로 보기 좋게 출력\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "cm = confusion_matrix(y_val, y_pred_val, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"실제_{l}\" for l in labels], columns=[f\"예측_{l}\" for l in labels])\n",
    "\n",
    "print(\"📊 Confusion Matrix\")\n",
    "display(cm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd1e59",
   "metadata": {},
   "source": [
    "### 파이프라인 모델링 (3단계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# local\n",
    "root_path = '../data/open'\n",
    "\n",
    "# colab\n",
    "# root_path = '/content/drive/MyDrive/12조 파이널프로젝트/data'\n",
    "\n",
    "# 데이터 불러오기\n",
    "\n",
    "#train_file = '201812_vif_drop_All'\n",
    "#train_file = '201812_corr_drop_All'\n",
    "#train_file = '201812_processed_All'\n",
    "train_file = 'vif_one_segment'\n",
    "#train_file = 'corr_one_segment'\n",
    "origin_df = pd.read_parquet(f'{root_path}/train/{train_file}.parquet')\n",
    "\n",
    "test_file = f'{root_path}/test/201812_processed_All.parquet'\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "y_origin = origin_df['Segment']\n",
    "\n",
    "### 학습/검증 분리 (인덱스 유지/ y_origin 클래스 비율에 맞춰서)\n",
    "train_df, score_df = train_test_split(origin_df, test_size=0.2, random_state=42, stratify=y_origin)\n",
    "\n",
    "print(\"✅ 단계 1: Segment == E vs Other\")\n",
    "\n",
    "# 분류 변경\n",
    "train_df[\"Segment1\"] = train_df[\"Segment\"].apply(lambda x: \"E\" if x == \"E\" else \"other\")\n",
    "\n",
    "exclude_cols = ['ID', '기준년월', 'Segment', 'Segment1']\n",
    "feature_cols = [\n",
    "    col for col in train_df.columns\n",
    "    if col not in exclude_cols\n",
    "]\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X = train_df[feature_cols]\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X.columns if col in test_df.columns]\n",
    "X_train = X[common_cols]\n",
    "X_test = test_df[common_cols]\n",
    "X_score = score_df[common_cols]\n",
    "\n",
    "y = train_df['Segment1']\n",
    "y_score = score_df['Segment']\n",
    "\n",
    "### 학습\n",
    "model1 = CatBoostClassifier(verbose=100, random_state=42)\n",
    "model1.fit(X_train, y)\n",
    "\n",
    "# 검증 성능 평가 (3단계까지 끝난 후 y_score과 비교하여 검증평가)\n",
    "score_df['Segment_pred'] = model1.predict(X_score)\n",
    "\n",
    "# 예측\n",
    "test_df['Segment_pred'] = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d52dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Segment_pred'].value_counts()\n",
    "score_df['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a72e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"✅ 단계 2: Segment == C or D vs Other (E 제거)\") \n",
    "\n",
    "train_df2 = train_df[train_df['Segment'] != 'E'].copy()\n",
    "test_df2 = test_df[test_df['Segment_pred'] == 'other'].copy()\n",
    "score_df2 = score_df[score_df['Segment_pred']== 'other'].copy()\n",
    "\n",
    "# 분류 변경\n",
    "train_df2['Segment1'] = train_df2['Segment'].apply(lambda x: x if x in ['C', 'D'] else 'other')\n",
    "\n",
    "exclude_cols = ['ID', '기준년월', 'Segment', 'Segment1']\n",
    "feature_cols = [\n",
    "    col for col in train_df2.columns\n",
    "    if col not in exclude_cols\n",
    "]\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X2 = train_df2[feature_cols]\n",
    "y2 = train_df2['Segment1']\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X2.columns if col in test_df2.columns]\n",
    "X_train2 = X2[common_cols]\n",
    "X_test2 = test_df2[common_cols]\n",
    "X_score2 = score_df2[common_cols]\n",
    "\n",
    "### 학습\n",
    "# 클래스별 가중치 적용\n",
    "classes = np.unique(train_df2['Segment1'])\n",
    "\n",
    "# 가중치 자동 계산\n",
    "#weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_df2['Segment1'])\n",
    "\n",
    "# 리스트로 변환\n",
    "#class_weights = weights.tolist()\n",
    "#print(dict(zip(classes, class_weights)))\n",
    "\n",
    "model2 = CatBoostClassifier(\n",
    "    verbose=100, \n",
    "    random_state=42#,\n",
    "    #class_weights=class_weights\n",
    ")\n",
    "\n",
    "model2.fit(X_train2, y2)\n",
    "\n",
    "# 검증 성능 평가 (3단계까지 끝난 후 y_origin_val과 비교하여 검증평가)\n",
    "score_df2['Segment_pred'] = model2.predict(X_score2).flatten()\n",
    "\n",
    "# 예측\n",
    "test_df2['Segment_pred'] = model2.predict(X_test2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce7509",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['Segment_pred'].value_counts()\n",
    "score_df2['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519addd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계 결과 score_df에 반영\n",
    "score_df.loc[score_df2.index, 'Segment_pred'] = score_df2['Segment_pred']\n",
    "\n",
    "# 예측 결과 병합\n",
    "# 중복된 ID 제거: 마지막 값을 기준으로 유지\n",
    "test_df.loc[test_df2.index, 'Segment_pred'] = test_df2['Segment_pred']\n",
    "    \n",
    "test_df['Segment_pred'].value_counts()\n",
    "score_df['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08136acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ 단계 3: Segment == A or B (C, D, E 제외)\")\n",
    "train_df3 = train_df[train_df['Segment'].isin(['A', 'B'])].copy()\n",
    "test_df3 = test_df[test_df['Segment_pred'] == 'other'].copy()\n",
    "score_df3 = score_df[score_df['Segment_pred']== 'other'].copy()\n",
    "\n",
    "# 분류 변경\n",
    "train_df3['Segment1'] = train_df3['Segment']\n",
    "\n",
    "exclude_cols = ['ID', '기준년월', 'Segment', 'Segment1']\n",
    "feature_cols = [\n",
    "    col for col in train_df3.columns\n",
    "    if col not in exclude_cols\n",
    "]\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X3 = train_df3[feature_cols]\n",
    "y3 = train_df3['Segment1']\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X3.columns if col in test_df3.columns]\n",
    "X_train3 = X3[common_cols]\n",
    "X_test3 = test_df3[common_cols]\n",
    "X_score3 = score_df3[common_cols]\n",
    "\n",
    "### 학습\n",
    "model3 = CatBoostClassifier(verbose=100, random_state=42)\n",
    "model3.fit(X_train3, y3)\n",
    "\n",
    "# 검증 성능 평가 (3단계까지 끝난 후 y_origin_val과 비교하여 검증평가)\n",
    "score_df3['Segment_pred'] = model3.predict(X_score3)\n",
    "\n",
    "# 예측\n",
    "test_df3['Segment_pred'] = model3.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df3['Segment_pred'].value_counts()\n",
    "score_df3['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddfa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 결과 병합\n",
    "score_df.loc[score_df3.index, 'Segment_pred'] = score_df3['Segment_pred']\n",
    "\n",
    "# 예측 결과 병합\n",
    "test_df.loc[test_df3.index, 'Segment_pred'] = test_df3['Segment_pred']\n",
    "\n",
    "# 최종 예측 결과 저장\n",
    "submission = test_df[['ID', 'Segment_pred']].copy()\n",
    "submission.rename(columns={'Segment_pred': 'Segment'}, inplace=True)\n",
    "submission.to_csv(f'../results/{train_file}_model3.csv', index=False)\n",
    "print(f\"{train_file}_model3 저장 완료!\")\n",
    "\n",
    "# 파이프라인 전체 성능 검사\n",
    "f1 = f1_score(y_score, score_df[\"Segment_pred\"], average='micro')\n",
    "print(f\"Validation F1 score (micro): {f1:.4f}\")\n",
    "\n",
    "# 혼동행렬\n",
    "# 혼동행렬을 DataFrame으로 보기 좋게 출력\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "cm = confusion_matrix(y_score, score_df[\"Segment_pred\"], labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"실제_{l}\" for l in labels], columns=[f\"예측_{l}\" for l in labels])\n",
    "\n",
    "print(\"📊 Confusion Matrix\")\n",
    "display(cm_df)\n",
    "\n",
    "class_accuracy = {}\n",
    "for i, label in enumerate(labels):\n",
    "    true_positive = cm[i, i]\n",
    "    total_actual = cm[i, :].sum()\n",
    "    acc = true_positive / total_actual if total_actual > 0 else 0\n",
    "    class_accuracy[label] = round(acc, 4)\n",
    "\n",
    "print(\"📊 Segment별 정확도:\")\n",
    "for seg, acc in class_accuracy.items():\n",
    "    print(f\"Segment {seg}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859d91c",
   "metadata": {},
   "source": [
    "### 파이프라인 모델링 (2단계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# local\n",
    "root_path = '../data/open'\n",
    "\n",
    "# colab\n",
    "# root_path = '/content/drive/MyDrive/12조 파이널프로젝트/data'\n",
    "\n",
    "#train_file = '201812_vif_drop_All'\n",
    "#train_file = '201812_corr_drop_All'\n",
    "#train_file = '201812_processed_All'\n",
    "train_file = 'vif_one_segment'\n",
    "origin_df = pd.read_parquet(f'{root_path}/train/{train_file}.parquet')\n",
    "\n",
    "test_file = f'{root_path}/test/201812_processed_All.parquet'\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "y_origin = origin_df['Segment']\n",
    "\n",
    "### 학습/검증 분리 (인덱스 유지/ y_origin 클래스 비율에 맞춰서)\n",
    "train_df, score_df = train_test_split(origin_df, test_size=0.2, random_state=42, stratify=y_origin)\n",
    "\n",
    "print(\"✅ 단계 1: Segment == C,D,E vs Other\")\n",
    "\n",
    "train_df[\"Segment1\"] = train_df[\"Segment\"].apply(lambda x: x if x in ['C', 'D', 'E'] else 'other')\n",
    "\n",
    "exclude_cols = ['ID', '기준년월', 'Segment', 'Segment1']\n",
    "feature_cols = [\n",
    "    col for col in train_df.columns\n",
    "    if col not in exclude_cols\n",
    "]\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X = train_df[feature_cols]\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X.columns if col in test_df.columns]\n",
    "X_train = X[common_cols]\n",
    "X_test = test_df[common_cols]\n",
    "X_score = score_df[common_cols]\n",
    "\n",
    "y = train_df['Segment1']\n",
    "y_score = score_df['Segment']\n",
    "\n",
    "### 학습\n",
    "'''\n",
    "# 클래스별 가중치 적용\n",
    "classes = np.unique(train_df['Segment1'])\n",
    "\n",
    "# 가중치 자동 계산\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_df['Segment1'])\n",
    "\n",
    "# 리스트로 변환\n",
    "class_weights = weights.tolist()\n",
    "print(dict(zip(classes, class_weights)))\n",
    "'''\n",
    "model1 = CatBoostClassifier(\n",
    "    verbose=100, \n",
    "    random_state=42\n",
    "    #class_weights=class_weights\n",
    ")\n",
    "model1.fit(X_train, y)\n",
    "\n",
    "# 검증 성능 평가\n",
    "score_df['Segment_pred'] = model1.predict(X_score).flatten()\n",
    "\n",
    "# 예측\n",
    "test_df['Segment_pred'] = model1.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795686a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Segment_pred'].value_counts()\n",
    "score_df['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ 단계 2: Segment == A or B \") \n",
    "\n",
    "train_df2 = train_df[train_df['Segment'].isin(['A', 'B'])].copy()\n",
    "test_df2 = test_df[test_df['Segment_pred'] == 'other'].copy()\n",
    "score_df2 = score_df[score_df['Segment_pred']== 'other'].copy()\n",
    "\n",
    "# 분류 변경\n",
    "train_df2['Segment1'] = train_df2['Segment']\n",
    "\n",
    "exclude_cols = ['ID', '기준년월', 'Segment', 'Segment1']\n",
    "feature_cols = [\n",
    "    col for col in train_df2.columns\n",
    "    if col not in exclude_cols\n",
    "]\n",
    "\n",
    "# 학습용 피처/타겟 정의\n",
    "X2 = train_df2[feature_cols]\n",
    "y2 = train_df2['Segment1']\n",
    "\n",
    "# X와 test_df 양쪽에 모두 존재하는 컬럼만 선택\n",
    "common_cols = [col for col in X2.columns if col in test_df2.columns]\n",
    "X_train2 = X2[common_cols]\n",
    "X_test2 = test_df2[common_cols]\n",
    "X_score2 = score_df2[common_cols]\n",
    "\n",
    "### 학습\n",
    "model2 = CatBoostClassifier(verbose=100, random_state=42)\n",
    "model2.fit(X_train2, y2)\n",
    "\n",
    "# 검증 성능 평가 (3단계까지 끝난 후 y_origin_val과 비교하여 검증평가)\n",
    "score_df2['Segment_pred'] = model2.predict(X_score2).flatten()\n",
    "\n",
    "# 예측\n",
    "test_df2['Segment_pred'] = model2.predict(X_test2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78729e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['Segment_pred'].value_counts()\n",
    "score_df2['Segment_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계 결과 score_df에 반영\n",
    "score_df.loc[score_df2.index, 'Segment_pred'] = score_df2['Segment_pred']\n",
    "\n",
    "# 예측 결과 병합\n",
    "test_df.loc[test_df2.index, 'Segment_pred'] = test_df2['Segment_pred']\n",
    "\n",
    "# 최종 예측 결과 저장\n",
    "submission = test_df[['ID', 'Segment_pred']].copy()\n",
    "submission.rename(columns={'Segment_pred': 'Segment'}, inplace=True)\n",
    "submission.to_csv(f'../results/{train_file}_model2.csv', index=False)\n",
    "print(f\"{train_file}_model2 저장 완료!\")\n",
    "\n",
    "#파이프라인 전체 성능 검사\n",
    "f1 = f1_score(y_score, score_df[\"Segment_pred\"], average='micro')\n",
    "print(f\"Validation F1 score (micro): {f1:.4f}\")\n",
    "\n",
    "# 혼동행렬\n",
    "# 혼동행렬을 DataFrame으로 보기 좋게 출력\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "cm = confusion_matrix(y_score, score_df[\"Segment_pred\"], labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"실제_{l}\" for l in labels], columns=[f\"예측_{l}\" for l in labels])\n",
    "\n",
    "print(\"📊 Confusion Matrix\")\n",
    "display(cm_df)\n",
    "\n",
    "class_accuracy = {}\n",
    "for i, label in enumerate(labels):\n",
    "    true_positive = cm[i, i]\n",
    "    total_actual = cm[i, :].sum()\n",
    "    acc = true_positive / total_actual if total_actual > 0 else 0\n",
    "    class_accuracy[label] = round(acc, 4)\n",
    "\n",
    "print(\"📊 Segment별 정확도:\")\n",
    "for seg, acc in class_accuracy.items():\n",
    "    print(f\"Segment {seg}: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
